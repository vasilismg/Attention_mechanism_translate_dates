{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate dates from human to machine format with attention mechanism\n",
    "\n",
    "This notebook is based on the programming assignment \"Neural machine translation\" of deeplearning.ai, course Sequence models, week Sequence models and Attention mechanism. The figure with the network architecture is taken from that assignment.\n",
    "\n",
    "We will build a model to translate human readable dates (\"25th of June, 2009\", \"03/30/1968\") into machine readable dates (\"2009-06-25\", \"1968-03-30\") using the attention mechanism.\n",
    "\n",
    "The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Use of unidirectional and bidirectional LSTM neural network architecture in TensorFlow\n",
    "- Apply the attention mechanism\n",
    "- Applying the concept of \"reuse\" for variables in TensorFlow\n",
    "- Use Adam optimizer with decay rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 18669.53it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('25 april 1982', '1982-04-25'),\n",
       " ('thursday september 20 1984', '1984-09-20'),\n",
       " ('sunday march 11 1973', '1973-03-11'),\n",
       " ('saturday april 29 1978', '1978-04-29'),\n",
       " ('saturday january 30 1982', '1982-01-30'),\n",
       " ('20.01.19', '2019-01-20'),\n",
       " ('monday july 7 1975', '1975-07-07'),\n",
       " ('october 9 1983', '1983-10-09'),\n",
       " ('tuesday july 2 1974', '1974-07-02'),\n",
       " ('21 aug 2000', '2000-08-21')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9990:] # list of tuples of (human readable date, machine readable date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '/': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12,\n",
       " '<pad>': 36,\n",
       " '<unk>': 35,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'y': 34}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab # python dictionary mapping all characters used in the human readable dates to an integer-valued index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab # python dictionary mapping all characters used in machine readable dates to an integer-valued index. \n",
    "# These indices are not necessarily consistent with human_vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '-',\n",
       " 1: '0',\n",
       " 2: '1',\n",
       " 3: '2',\n",
       " 4: '3',\n",
       " 5: '4',\n",
       " 6: '5',\n",
       " 7: '6',\n",
       " 8: '7',\n",
       " 9: '8',\n",
       " 10: '9'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_machine_vocab # inverse dictionary of machine_vocab, mapping from indices back to characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the data and map the raw text data into the index values. We will also use Tx=30 (which we assume is the maximum length of the human readable date; if we get a shorter date, it is further padded to $T_x$ values with a special character < pad >; if we get a longer input, we would have to truncate it) and Ty=10 (since \"YYYY-MM-DD\" is 10 characters long). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
    "    \n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "\n",
    "    return X, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (10000, 30)\n",
      "Y_train.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X_train_original, Y_train_original = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X_train.shape:\", X_train_original.shape)\n",
    "print(\"Y_train.shape:\", Y_train_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X_train_original[index])\n",
    "print(\"Target after preprocessing (indices):\", Y_train_original[index])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture and Attention mechanism\n",
    "\n",
    "The diagram on the left shows the attention model. The diagram on the right shows what one \"Attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$, which are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). \n",
    "\n",
    "\n",
    "<img src=\"images/attention2.png\" style=\"width:500;height:500px;\"> <br>\n",
    "\n",
    "\n",
    "<caption><center> Neural machine translation with attention</center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):   \n",
    "    \n",
    "  used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    \n",
    "    inputs_ = tf.placeholder(tf.int32,[None,None],name='inputs_')\n",
    "    labels_ = tf.placeholder(tf.int32,[None,None],name='labels_')\n",
    "    \n",
    "    return inputs_, labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_post_attention_lstm(lstm_size, lstm_layers, batch_size):\n",
    "    \n",
    "    # Basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "        \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm for _ in range(lstm_layers)])\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bidirectional_lstm(lstm_size, lstm_layers, batch_size):\n",
    "    \n",
    "    # Basic LSTM cell\n",
    "    lstm_fw = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "    lstm_bw = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell_fw = tf.contrib.rnn.MultiRNNCell([lstm_fw for _ in range(lstm_layers)])\n",
    "    cell_bw = tf.contrib.rnn.MultiRNNCell([lstm_bw for _ in range(lstm_layers)])\n",
    "        \n",
    "    return cell_fw, cell_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(bidirectional_outputs_concat, s_prev, Tx, reuse, scope1,scope2):\n",
    "    \n",
    "    s_prev_repeator=tf.tile(tf.expand_dims(s_prev,1), [1, Tx, 1])\n",
    "    bidirectional_outputs_sprev_concat=tf.concat([bidirectional_outputs_concat,s_prev_repeator],axis=2)\n",
    "        \n",
    "    densor1=tf.contrib.layers.fully_connected(bidirectional_outputs_sprev_concat, 10, activation_fn=tf.nn.tanh,\n",
    "                                             reuse=reuse, scope=scope1, \n",
    "                                              weights_initializer = tf.keras.initializers.glorot_uniform())\n",
    "    \n",
    "    densor2=tf.contrib.layers.fully_connected(densor1, 1, activation_fn=tf.nn.relu,reuse=reuse, scope=scope2,\n",
    "                                             weights_initializer = tf.keras.initializers.glorot_uniform())\n",
    "    \n",
    "    alphas=tf.nn.softmax(densor2,axis=1)\n",
    "    context=tf.reduce_sum( tf.multiply(alphas, bidirectional_outputs_concat),axis=1, keep_dims=True )\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(predictions, targets, num_classes, Ty):\n",
    "        \n",
    "    # num_classes is len(machine_vocab)    \n",
    "    y_one_hot = tf.one_hot(targets, depth=num_classes)\n",
    "    y_one_hot_swap=tf.transpose(y_one_hot, [1, 0, 2])\n",
    "\n",
    "    \n",
    "    total_loss = None\n",
    "    for kkk in range(Ty):\n",
    "        output_loss = tf.keras.losses.categorical_crossentropy(y_true=y_one_hot_swap[kkk], y_pred=predictions[kkk], from_logits=False)\n",
    "        \n",
    "        if total_loss is None:\n",
    "            total_loss = output_loss\n",
    "        else:\n",
    "            total_loss += output_loss\n",
    "        \n",
    "    loss = tf.reduce_mean(total_loss)\n",
    "    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_accuracy(predictions, targets, num_classes):\n",
    "        \n",
    "    # num_classes is len(machine_vocab)    \n",
    "    y_one_hot = tf.one_hot(targets, depth=num_classes)\n",
    "    y_one_hot_swap=tf.transpose(y_one_hot, [1, 0, 2])\n",
    "    y_reshaped = tf.reshape(y_one_hot_swap,[-1,num_classes])\n",
    "        \n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.reduce_all(tf.reduce_all(tf.equal(y_one_hot_swap,tf.round(predictions)),0),1),tf.float32))\n",
    "        \n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, decay_rate):\n",
    "    \n",
    "    global_step = tf.Variable(1, trainable=False) \n",
    "    \n",
    "    learning_rate = learning_rate / (1. + decay_rate * tf.cast(global_step,tf.float32))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "     \n",
    "    return optimizer, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class machine_translation_model:\n",
    "    \n",
    "    def __init__(self, human_vocab_size, batch_size, \n",
    "                       bi_lstm_size, bi_lstm_layers, post_attention_lstm_size, post_attention_lstm_layers,\n",
    "                         learning_rate, Tx, Ty, test_mode=False):\n",
    "        \n",
    "        if (test_mode==True):\n",
    "            batch_size=1\n",
    "            reuse=tf.AUTO_REUSE\n",
    "        else:\n",
    "            reuse=False\n",
    "            \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs_, self.labels_ = build_inputs()\n",
    "\n",
    "        # one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs_, human_vocab_size)\n",
    "        \n",
    "        logits_list=[]\n",
    "        predictions_list=[]\n",
    "        \n",
    "        # Build the Bidirectional LSTM cell\n",
    "        cell_fw, cell_bw = build_bidirectional_lstm(bi_lstm_size, bi_lstm_layers, batch_size)\n",
    "                \n",
    "        bidirectional_outputs, bidirectional_output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, \n",
    "                                                        x_one_hot, sequence_length=length(x_one_hot), dtype=tf.float32)\n",
    "            \n",
    "        self.bidirectional_outputs=bidirectional_outputs\n",
    "        self.bidirectional_outputs_concat=tf.concat([self.bidirectional_outputs[0],\n",
    "                                                     self.bidirectional_outputs[1]],axis=2)\n",
    "         \n",
    "        # s_prev for 1st step, equal to all 0s\n",
    "        post_attention_cell, self.post_attention_initial_state = build_post_attention_lstm(post_attention_lstm_size,\n",
    "                                                                            post_attention_lstm_layers, batch_size)\n",
    "        \n",
    "        self.s_prev=self.post_attention_initial_state[0][1]\n",
    "        self.post_attention_state=self.post_attention_initial_state\n",
    "        \n",
    "        scope1='densor1'\n",
    "        scope2='densor2'\n",
    "        \n",
    "        # Iterate for Ty steps\n",
    "        for t in range(Ty):\n",
    "            \n",
    "            if (t>=1):\n",
    "                reuse = True\n",
    "            \n",
    "            # Perform one step of the attention mechanism to get back the context vector at step t \n",
    "            self.context = one_step_attention(self.bidirectional_outputs_concat, self.s_prev, Tx, reuse, scope1, scope2)\n",
    "        \n",
    "            # Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "            self.post_attention_lstm_output, state = tf.nn.dynamic_rnn(post_attention_cell, \n",
    "                                                        self.context, initial_state=self.post_attention_state)\n",
    "            \n",
    "            self.post_attention_state = state\n",
    "            self.s_prev = self.post_attention_state[0][1]\n",
    "        \n",
    "            # Apply fully connected layer to the hidden state output of the post-attention LSTM\n",
    "            self.logits = tf.contrib.layers.fully_connected(self.post_attention_lstm_output[:,0,:], \n",
    "                            len(machine_vocab), activation_fn=None,reuse=reuse, \n",
    "                            scope='softmax', weights_initializer = tf.keras.initializers.glorot_uniform())\n",
    "\n",
    "            self.predictions = tf.nn.softmax(self.logits,axis=1)\n",
    "            \n",
    "            logits_list.append(self.logits)\n",
    "            predictions_list.append(self.predictions)\n",
    "        \n",
    "\n",
    "        self.logits_list = tf.stack(logits_list)\n",
    "        self.predictions_list = tf.stack(predictions_list)\n",
    "        \n",
    "        self.loss = build_loss(self.predictions_list, self.labels_ , len(machine_vocab), Ty)\n",
    "       \n",
    "        self.accuracy = build_accuracy(self.predictions_list, self.labels_ , len(machine_vocab))\n",
    "        self.optimizer, self.learning_rate = build_optimizer(self.loss, learning_rate, decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_attention_lstm_size = 64\n",
    "post_attention_lstm_layers = 1\n",
    "bi_lstm_size = 32\n",
    "bi_lstm_layers = 1\n",
    "batch_size = 100\n",
    "human_vocab_size = len(human_vocab)\n",
    "learning_rate = 0.005\n",
    "decay_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0217 12:01:08.767188 140277535123264 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0217 12:01:08.767970 140277535123264 deprecation.py:323] From <ipython-input-16-69db57d9c2fb>:4: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0217 12:01:08.768779 140277535123264 deprecation.py:323] From <ipython-input-16-69db57d9c2fb>:8: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0217 12:01:08.774282 140277535123264 deprecation.py:323] From <ipython-input-21-a1444570a6d0>:29: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0217 12:01:08.775113 140277535123264 deprecation.py:323] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0217 12:01:09.022867 140277535123264 deprecation.py:506] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0217 12:01:09.029967 140277535123264 deprecation.py:506] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0217 12:01:09.300918 140277535123264 deprecation.py:323] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0217 12:01:09.770888 140277535123264 deprecation.py:506] From <ipython-input-17-cc4b71c5a1ec>:12: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(69, 128) dtype=float32_ref>\n",
      "shape of weight matrix:  (69, 128)\n",
      "number of trainable parameters:  8832\n",
      "------------------------------\n",
      "<tf.Variable 'bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "shape of weight matrix:  (128,)\n",
      "number of trainable parameters:  128\n",
      "------------------------------\n",
      "<tf.Variable 'bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(69, 128) dtype=float32_ref>\n",
      "shape of weight matrix:  (69, 128)\n",
      "number of trainable parameters:  8832\n",
      "------------------------------\n",
      "<tf.Variable 'bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "shape of weight matrix:  (128,)\n",
      "number of trainable parameters:  128\n",
      "------------------------------\n",
      "<tf.Variable 'densor1/weights:0' shape=(128, 10) dtype=float32_ref>\n",
      "shape of weight matrix:  (128, 10)\n",
      "number of trainable parameters:  1280\n",
      "------------------------------\n",
      "<tf.Variable 'densor1/biases:0' shape=(10,) dtype=float32_ref>\n",
      "shape of weight matrix:  (10,)\n",
      "number of trainable parameters:  10\n",
      "------------------------------\n",
      "<tf.Variable 'densor2/weights:0' shape=(10, 1) dtype=float32_ref>\n",
      "shape of weight matrix:  (10, 1)\n",
      "number of trainable parameters:  10\n",
      "------------------------------\n",
      "<tf.Variable 'densor2/biases:0' shape=(1,) dtype=float32_ref>\n",
      "shape of weight matrix:  (1,)\n",
      "number of trainable parameters:  1\n",
      "------------------------------\n",
      "<tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(128, 256) dtype=float32_ref>\n",
      "shape of weight matrix:  (128, 256)\n",
      "number of trainable parameters:  32768\n",
      "------------------------------\n",
      "<tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>\n",
      "shape of weight matrix:  (256,)\n",
      "number of trainable parameters:  256\n",
      "------------------------------\n",
      "<tf.Variable 'softmax/weights:0' shape=(64, 11) dtype=float32_ref>\n",
      "shape of weight matrix:  (64, 11)\n",
      "number of trainable parameters:  704\n",
      "------------------------------\n",
      "<tf.Variable 'softmax/biases:0' shape=(11,) dtype=float32_ref>\n",
      "shape of weight matrix:  (11,)\n",
      "number of trainable parameters:  11\n",
      "------------------------------\n",
      "total number of trainable parameters:  52960\n"
     ]
    }
   ],
   "source": [
    "model = machine_translation_model(human_vocab_size=human_vocab_size, batch_size=batch_size, \n",
    "                       bi_lstm_size=bi_lstm_size, bi_lstm_layers=bi_lstm_layers, post_attention_lstm_size=post_attention_lstm_size,\n",
    "                        post_attention_lstm_layers=post_attention_lstm_layers, learning_rate=learning_rate, Tx=Tx, Ty=Ty)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        print(variable)\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print('shape of weight matrix: ',shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print('number of trainable parameters: ',variable_parameters)\n",
    "        print('------------------------------')\n",
    "        total_parameters += variable_parameters\n",
    "    print('total number of trainable parameters: ',total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explanation of weight matrices shapes\n",
    "\n",
    "* The training variables are:\n",
    "    * Variable:  bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, Shape:  (68, 128)\n",
    "       \n",
    "      68 because the input to each LSTM gate is the concatenation of inputs of size (100,36) and the 32 LSTM nodes, thus (100,68)\n",
    "      \n",
    "      128 because LSTM has 4 gates with 32 nodes and thus 4*32=128\n",
    "     \n",
    "    * Variable:  rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, Shape: (128, 256)\n",
    "      \n",
    "      This refers to the post-attention LSTM, which has inputs conext and s_prev\n",
    "      context has shape (100,1,64), since bidirectional_outputs_concat has shape (100,30,64)\n",
    "      \n",
    "      128 because 64 from context and 64 from LSTM nodes\n",
    "      \n",
    "      256 because LSTM has 4 gates with 64 nodes and thus 4*64=256\n",
    "      \n",
    "    * Variable:  softmax/softmax_w:0, Shape: (64, 11)\n",
    "    \n",
    "      64 because the input to softmax is the output of post-attention LSTM which has 64 nodes\n",
    "      \n",
    "      11 are the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000 Train loss (mean) : 16.3586063385 accuracy: 0.000000 learning rate : 0.00250000\n",
      "Epoch: 11/5000 Train loss (mean) : 2.4202771187 accuracy: 0.358100 learning rate : 0.00041667\n",
      "Epoch: 21/5000 Train loss (mean) : 0.9225839972 accuracy: 0.797500 learning rate : 0.00022727\n",
      "Epoch: 31/5000 Train loss (mean) : 0.5369058251 accuracy: 0.891500 learning rate : 0.00015625\n",
      "Epoch: 41/5000 Train loss (mean) : 0.3609484732 accuracy: 0.925200 learning rate : 0.00011905\n",
      "Epoch: 51/5000 Train loss (mean) : 0.2550993264 accuracy: 0.945600 learning rate : 0.00009615\n",
      "Epoch: 61/5000 Train loss (mean) : 0.1868159473 accuracy: 0.961300 learning rate : 0.00008065\n",
      "Epoch: 71/5000 Train loss (mean) : 0.1415593773 accuracy: 0.972300 learning rate : 0.00006944\n",
      "Epoch: 81/5000 Train loss (mean) : 0.1087174863 accuracy: 0.981500 learning rate : 0.00006098\n",
      "Epoch: 91/5000 Train loss (mean) : 0.0854126960 accuracy: 0.986900 learning rate : 0.00005435\n",
      "Epoch: 101/5000 Train loss (mean) : 0.0683096275 accuracy: 0.991000 learning rate : 0.00004902\n",
      "Epoch: 111/5000 Train loss (mean) : 0.0551395752 accuracy: 0.993900 learning rate : 0.00004464\n",
      "Epoch: 121/5000 Train loss (mean) : 0.0453086756 accuracy: 0.995800 learning rate : 0.00004098\n",
      "Epoch: 131/5000 Train loss (mean) : 0.0371121131 accuracy: 0.997600 learning rate : 0.00003788\n",
      "Epoch: 141/5000 Train loss (mean) : 0.0308672786 accuracy: 0.998300 learning rate : 0.00003521\n",
      "Epoch: 151/5000 Train loss (mean) : 0.0257653911 accuracy: 0.998800 learning rate : 0.00003289\n",
      "Epoch: 161/5000 Train loss (mean) : 0.0213861540 accuracy: 0.999300 learning rate : 0.00003086\n",
      "Epoch: 171/5000 Train loss (mean) : 0.0179642942 accuracy: 0.999800 learning rate : 0.00002907\n",
      "Epoch: 181/5000 Train loss (mean) : 0.0152875241 accuracy: 1.000000 learning rate : 0.00002747\n",
      "Epoch: 191/5000 Train loss (mean) : 0.0130449869 accuracy: 1.000000 learning rate : 0.00002604\n",
      "Epoch: 201/5000 Train loss (mean) : 0.0111104278 accuracy: 1.000000 learning rate : 0.00002475\n",
      "Epoch: 401/5000 Train loss (mean) : 0.0007797161 accuracy: 1.000000 learning rate : 0.00001244\n",
      "Epoch: 601/5000 Train loss (mean) : 0.0000919841 accuracy: 1.000000 learning rate : 0.00000831\n",
      "Epoch: 801/5000 Train loss (mean) : 0.0000151940 accuracy: 1.000000 learning rate : 0.00000623\n",
      "Epoch: 1001/5000 Train loss (mean) : 0.0000037643 accuracy: 1.000000 learning rate : 0.00000499\n",
      "Epoch: 1201/5000 Train loss (mean) : 0.0000017497 accuracy: 1.000000 learning rate : 0.00000416\n",
      "Epoch: 1401/5000 Train loss (mean) : 0.0000013507 accuracy: 1.000000 learning rate : 0.00000357\n",
      "Epoch: 1601/5000 Train loss (mean) : 0.0000012523 accuracy: 1.000000 learning rate : 0.00000312\n",
      "Epoch: 1801/5000 Train loss (mean) : 0.0000012208 accuracy: 1.000000 learning rate : 0.00000277\n",
      "Epoch: 2001/5000 Train loss (mean) : 0.0000012079 accuracy: 1.000000 learning rate : 0.00000250\n",
      "Epoch: 2501/5000 Train loss (mean) : 0.0000011975 accuracy: 1.000000 learning rate : 0.00000200\n",
      "Epoch: 3001/5000 Train loss (mean) : 0.0000011947 accuracy: 1.000000 learning rate : 0.00000167\n",
      "Epoch: 3501/5000 Train loss (mean) : 0.0000011936 accuracy: 1.000000 learning rate : 0.00000143\n",
      "Epoch: 4001/5000 Train loss (mean) : 0.0000011930 accuracy: 1.000000 learning rate : 0.00000125\n",
      "Epoch: 4501/5000 Train loss (mean) : 0.0000011927 accuracy: 1.000000 learning rate : 0.00000111\n",
      "duration: 28801.4 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "nb_epochs = 5000\n",
    "epochs = nb_epochs\n",
    "\n",
    "model = machine_translation_model(human_vocab_size=human_vocab_size, batch_size=batch_size, \n",
    "                       bi_lstm_size=bi_lstm_size, bi_lstm_layers=bi_lstm_layers, post_attention_lstm_size=post_attention_lstm_size,\n",
    "                        post_attention_lstm_layers=post_attention_lstm_layers, learning_rate=learning_rate, Tx=Tx, Ty=Ty)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=epochs) \n",
    "\n",
    "train_loss_mean = []\n",
    "train_acc_mean = []\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        \n",
    "        post_attention_state_val = sess.run(model.post_attention_initial_state)\n",
    "         \n",
    "        # shuffling the data\n",
    "        permutated = np.arange(X_train_original.shape[0])\n",
    "        np.random.shuffle(permutated)\n",
    "        X_train = X_train_original[permutated]\n",
    "        Y_train = Y_train_original[permutated]\n",
    "\n",
    "        for (x_train, y_train) in get_batches(X_train, Y_train, batch_size):\n",
    "            feed = {model.inputs_: x_train,\n",
    "                   model.labels_: y_train,\n",
    "                   model.post_attention_initial_state: post_attention_state_val}\n",
    "                       \n",
    "            batch_loss, batch_accuracy,_,batch_learning_rate = sess.run([model.loss,\n",
    "                                                        model.accuracy,\n",
    "                                                        model.optimizer, model.learning_rate],\n",
    "                                feed_dict=feed)\n",
    "           \n",
    "            train_loss.append(batch_loss)\n",
    "            train_acc.append(batch_accuracy)\n",
    "                                    \n",
    "        if (e<=200):\n",
    "            if (e%10==0):\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Train loss (mean) : {:.10f}\".format(np.mean(train_loss)),\n",
    "                      \"accuracy: {:.6f}\".format(np.mean(train_acc)),\n",
    "                       \"learning rate : {:.8f}\".format(batch_learning_rate))\n",
    "        elif (e>200 and e < 2000):\n",
    "            if (e%200==0):\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Train loss (mean) : {:.10f}\".format(np.mean(train_loss)),\n",
    "                      \"accuracy: {:.6f}\".format(np.mean(train_acc)),\n",
    "                       \"learning rate : {:.8f}\".format(batch_learning_rate))\n",
    "        else:\n",
    "            if (e%500==0):\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Train loss (mean) : {:.10f}\".format(np.mean(train_loss)),\n",
    "                      \"accuracy: {:.6f}\".format(np.mean(train_acc)),\n",
    "                       \"learning rate : {:.8f}\".format(batch_learning_rate))            \n",
    "            \n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "\n",
    "        if (e%20 == 0):\n",
    "            saver.save(sess, \"checkpoints/epoch_{}.ckpt\".format(e+1))\n",
    "              \n",
    "    duration=time.time()-start_time\n",
    "    print(\"duration: {:.1f} sec\".format(duration))\n",
    "    saver.save(sess, \"checkpoints/translation.ckpt\")\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1,epochs+1), train_loss_mean)\n",
    "plt.ylabel('mean loss per epoch')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1,epochs+1), train_loss_mean)\n",
    "plt.ylabel('mean loss per epoch - log scale')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale('log')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1,epochs+1), train_acc_mean)\n",
    "plt.ylabel('mean accuracy per epoch')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on unseen examples (i.e. human readable dates)\n",
    "Out of the 30 given unseen dates it predicts correctly the 23 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "\n",
      "source: 5 April 09\n",
      "output: 2009-04-05\n",
      "\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n",
      "\n",
      "source: 21st of August 2016\n",
      "output: 2016-08-21\n",
      "\n",
      "source: August 21 2016\n",
      "output: 2016-08-21\n",
      "\n",
      "source: 3/27/70\n",
      "output: 1970-03-27\n",
      "\n",
      "source: 18.10.89\n",
      "output: 1989-10-18\n",
      "\n",
      "source: saturday september 29 1984\n",
      "output: 1984-09-29\n",
      "\n",
      "source: 8 01 16\n",
      "output: 2016-01-08\n",
      "\n",
      "source: 12th of November 2032\n",
      "output: 2033-01-12\n",
      "\n",
      "source: 11th of November 2010\n",
      "output: 2010-11-11\n",
      "\n",
      "source: April 3rd 2010\n",
      "output: 2010-04-03\n",
      "\n",
      "source: April 2nd 2010\n",
      "output: 2010-04-02\n",
      "\n",
      "source: April 1st 2010\n",
      "output: 2010-04-01\n",
      "\n",
      "source: December 3rd 2010\n",
      "output: 2010-12-03\n",
      "\n",
      "source: December 3th 2010\n",
      "output: 2010-02-03\n",
      "\n",
      "source: 3rd of December 2010\n",
      "output: 2010-12-01\n",
      "\n",
      "source: 4th of December 2010\n",
      "output: 2010-12-04\n",
      "\n",
      "source: December 4th 2010\n",
      "output: 2010-02-04\n",
      "\n",
      "source: December 5th 2010\n",
      "output: 2010-02-05\n",
      "\n",
      "source: 6th of December 2010\n",
      "output: 2010-12-06\n",
      "\n",
      "source: 11th of August 2016\n",
      "output: 2016-08-11\n",
      "\n",
      "source: Friday 3 May 1995\n",
      "output: 1995-05-03\n",
      "\n",
      "source: 10th June 1900\n",
      "output: 2000-06-01\n",
      "\n",
      "source: 10th June 1980\n",
      "output: 1980-06-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', \n",
    "            'March 3 2001', 'March 3rd 2001', '1 March 2001', '21st of August 2016', 'August 21 2016',\n",
    "            '3/27/70', '18.10.89','saturday september 29 1984', '8 01 16', '12th of November 2032',\n",
    "           '11th of November 2010', 'April 3rd 2010', 'April 2nd 2010', 'April 1st 2010', 'December 3rd 2010', \n",
    "            'December 3th 2010', '3rd of December 2010', '4th of December 2010', 'December 4th 2010', 'December 5th 2010',\n",
    "           '6th of December 2010', '11th of August 2016', 'Friday 3 May 1995', '10th June 1900','10th June 1980']\n",
    "\n",
    "model = machine_translation_model(human_vocab_size=human_vocab_size, batch_size=1,\n",
    "                       bi_lstm_size=bi_lstm_size, bi_lstm_layers=bi_lstm_layers, post_attention_lstm_size=post_attention_lstm_size,\n",
    "                        post_attention_lstm_layers=post_attention_lstm_layers, learning_rate=learning_rate, Tx=Tx, Ty=Ty,\n",
    "                                     test_mode=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    test_post_attention_state_val = sess.run(model.post_attention_initial_state)\n",
    "        \n",
    "    for example in EXAMPLES:\n",
    "        source = string_to_int(example, Tx, human_vocab)   \n",
    "        x=np.array(source)\n",
    "        x=x.reshape(1,-1)\n",
    "    \n",
    "        batches = get_batches(X_train_original[:1], Y_train_original[:1], 1)\n",
    "        x1, y = next(batches)\n",
    "    \n",
    "        feed = {model.inputs_: x,\n",
    "                   model.labels_: y,\n",
    "                   model.post_attention_initial_state: test_post_attention_state_val}\n",
    "            \n",
    "            \n",
    "        test_predictions_list = sess.run(model.predictions_list,\n",
    "                                feed_dict=feed)\n",
    "        \n",
    "        prediction = np.argmax(test_predictions_list, axis = -1)\n",
    "        output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "        print(\"source:\", example)\n",
    "        print(\"output:\", ''.join(output))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
