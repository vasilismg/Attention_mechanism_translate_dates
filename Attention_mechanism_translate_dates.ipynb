{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate dates from human to machine format with attention mechanism\n",
    "\n",
    "This notebook is based on the programming assignment \"Neural machine translation\" of deeplearning.ai, course Sequence models, week Sequence models and Attention mechanism. It was implemented in Keras and I reimplemented it using TensorFlow 1.14. The figure with the network architecture is taken from that assignment.\n",
    "\n",
    "We will build a model to translate human readable dates (\"25th of June, 2009\", \"03/30/1968\") into machine readable dates (\"2009-06-25\", \"1968-03-30\") using the attention mechanism.\n",
    "\n",
    "The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Use of unidirectional and bidirectional LSTM neural network architecture in TensorFlow\n",
    "- Apply the attention mechanism\n",
    "- Applying the concept of \"reuse\" for variables in TensorFlow\n",
    "- Use Adam optimizer with decay rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 22073.52it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('25 april 1982', '1982-04-25'),\n",
       " ('thursday september 20 1984', '1984-09-20'),\n",
       " ('sunday march 11 1973', '1973-03-11'),\n",
       " ('saturday april 29 1978', '1978-04-29'),\n",
       " ('saturday january 30 1982', '1982-01-30'),\n",
       " ('20.01.19', '2019-01-20'),\n",
       " ('monday july 7 1975', '1975-07-07'),\n",
       " ('october 9 1983', '1983-10-09'),\n",
       " ('tuesday july 2 1974', '1974-07-02'),\n",
       " ('21 aug 2000', '2000-08-21')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[9990:] # list of tuples of (human readable date, machine readable date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '/': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12,\n",
       " '<pad>': 36,\n",
       " '<unk>': 35,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'y': 34}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab # python dictionary mapping all characters used in the human readable dates to an integer-valued index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-': 0,\n",
       " '0': 1,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '6': 7,\n",
       " '7': 8,\n",
       " '8': 9,\n",
       " '9': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_vocab # python dictionary mapping all characters used in machine readable dates to an integer-valued index. \n",
    "# These indices are not necessarily consistent with human_vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '-',\n",
       " 1: '0',\n",
       " 2: '1',\n",
       " 3: '2',\n",
       " 4: '3',\n",
       " 5: '4',\n",
       " 6: '5',\n",
       " 7: '6',\n",
       " 8: '7',\n",
       " 9: '8',\n",
       " 10: '9'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_machine_vocab # inverse dictionary of machine_vocab, mapping from indices back to characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess the data and map the raw text data into the index values. We will also use Tx=30 (which we assume is the maximum length of the human readable date; if we get a shorter date, it is further padded to $T_x$ values with a special character < pad >; if we get a longer input, we would have to truncate it) and Ty=10 (since \"YYYY-MM-DD\" is 10 characters long). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
    "    \n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
    "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
    "\n",
    "    return X, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (10000, 30)\n",
      "Y_train.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X_train_original, Y_train_original = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X_train.shape:\", X_train_original.shape)\n",
    "print(\"Y_train.shape:\", Y_train_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X_train_original[index])\n",
    "print(\"Target after preprocessing (indices):\", Y_train_original[index])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture and Attention mechanism\n",
    "\n",
    "The diagram on the left shows the attention model. The diagram on the right shows what one \"Attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$, which are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). Both diagrams are taken from the programming assignment \"Neural machine translation\" of deeplearning.ai\n",
    "\n",
    "\n",
    "<img src=\"images/attention.png\" style=\"width:500;height:500px;\"> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):   \n",
    "    \n",
    "  used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs():\n",
    "    \n",
    "    inputs_ = tf.placeholder(tf.int32,[None,None],name='inputs_')\n",
    "    labels_ = tf.placeholder(tf.int32,[None,None],name='labels_')\n",
    "    \n",
    "    return inputs_, labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_post_attention_lstm(lstm_size, lstm_layers, batch_size):\n",
    "    \n",
    "    # Basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "        \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm for _ in range(lstm_layers)])\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bidirectional_lstm(lstm_size, lstm_layers, batch_size):\n",
    "    \n",
    "    # Basic LSTM cell\n",
    "    lstm_fw = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "    lstm_bw = tf.contrib.rnn.BasicLSTMCell(lstm_size) \n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell_fw = tf.contrib.rnn.MultiRNNCell([lstm_fw for _ in range(lstm_layers)])\n",
    "    cell_bw = tf.contrib.rnn.MultiRNNCell([lstm_bw for _ in range(lstm_layers)])\n",
    "        \n",
    "    return cell_fw, cell_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_step_attention(bidirectional_outputs_concat, s_prev, Tx, reuse, scope1,scope2):\n",
    "    \n",
    "    s_prev_repeator=tf.tile(tf.expand_dims(s_prev,1), [1, Tx, 1])\n",
    "    bidirectional_outputs_sprev_concat=tf.concat([bidirectional_outputs_concat,s_prev_repeator],axis=2)\n",
    "        \n",
    "    densor1=tf.contrib.layers.fully_connected(bidirectional_outputs_sprev_concat, 10, activation_fn=tf.nn.tanh,\n",
    "                                             reuse=reuse, scope=scope1, \n",
    "                                              weights_initializer = tf.keras.initializers.glorot_uniform())\n",
    "    \n",
    "    densor2=tf.contrib.layers.fully_connected(densor1, 1, activation_fn=tf.nn.relu,reuse=reuse, scope=scope2,\n",
    "                                             weights_initializer = tf.keras.initializers.glorot_uniform())\n",
    "    \n",
    "    alphas=tf.nn.softmax(densor2,axis=1)\n",
    "    context=tf.reduce_sum( tf.multiply(alphas, bidirectional_outputs_concat),axis=1, keep_dims=True )\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(predictions, targets, num_classes, Ty):\n",
    "        \n",
    "    # num_classes is len(machine_vocab)    \n",
    "    y_one_hot = tf.one_hot(targets, depth=num_classes)\n",
    "    y_one_hot_swap=tf.transpose(y_one_hot, [1, 0, 2])\n",
    "   \n",
    "    total_loss = None\n",
    "    for kkk in range(Ty):\n",
    "        output_loss = tf.keras.losses.categorical_crossentropy(y_true=y_one_hot_swap[kkk], y_pred=predictions[kkk], from_logits=False)\n",
    "        \n",
    "        if total_loss is None:\n",
    "            total_loss = output_loss\n",
    "        else:\n",
    "            total_loss += output_loss\n",
    "        \n",
    "    loss = tf.reduce_mean(total_loss)\n",
    "    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_accuracy(predictions, targets, num_classes):\n",
    "        \n",
    "    # num_classes is len(machine_vocab)    \n",
    "    y_one_hot = tf.one_hot(targets, depth=num_classes)\n",
    "    y_one_hot_swap=tf.transpose(y_one_hot, [1, 0, 2])\n",
    "        \n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.reduce_all(tf.reduce_all(tf.equal(y_one_hot_swap,tf.round(predictions)),0),1),tf.float32))\n",
    "        \n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, decay_rate):\n",
    "    \n",
    "    global_step = tf.Variable(1, trainable=False) \n",
    "    \n",
    "    learning_rate = learning_rate / (1. + decay_rate * tf.cast(global_step,tf.float32))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "     \n",
    "    return optimizer, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class machine_translation_model:\n",
    "    \n",
    "    def __init__(self, human_vocab_size, batch_size, \n",
    "                       bi_lstm_size, bi_lstm_layers, post_attention_lstm_size, post_attention_lstm_layers,\n",
    "                         learning_rate, Tx, Ty, test_mode=False):\n",
    "        \n",
    "        if (test_mode==True):\n",
    "            batch_size=1\n",
    "            reuse=tf.AUTO_REUSE\n",
    "        else:\n",
    "            reuse=False\n",
    "            \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        # Build the input placeholder tensors\n",
    "        self.inputs_, self.labels_ = build_inputs()\n",
    "\n",
    "        # one-hot encode the input tokens\n",
    "        x_one_hot = tf.one_hot(self.inputs_, human_vocab_size)\n",
    "        \n",
    "        logits_list=[]\n",
    "        predictions_list=[]\n",
    "        \n",
    "        # Build the Bidirectional LSTM cell\n",
    "        cell_fw, cell_bw = build_bidirectional_lstm(bi_lstm_size, bi_lstm_layers, batch_size)\n",
    "                \n",
    "        bidirectional_outputs, bidirectional_output_states = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, \n",
    "                                                        x_one_hot, sequence_length=length(x_one_hot), dtype=tf.float32)\n",
    "            \n",
    "        self.bidirectional_outputs=bidirectional_outputs\n",
    "        self.bidirectional_outputs_concat=tf.concat([self.bidirectional_outputs[0],\n",
    "                                                     self.bidirectional_outputs[1]],axis=2)\n",
    "         \n",
    "        # s_prev for 1st step, equal to all 0s\n",
    "        post_attention_cell, self.post_attention_initial_state = build_post_attention_lstm(post_attention_lstm_size,\n",
    "                                                                            post_attention_lstm_layers, batch_size)\n",
    "        \n",
    "        self.s_prev=self.post_attention_initial_state[0][1]\n",
    "        self.post_attention_state=self.post_attention_initial_state\n",
    "        \n",
    "        scope1='densor1'\n",
    "        scope2='densor2'\n",
    "        \n",
    "        # Iterate for Ty steps\n",
    "        for t in range(Ty):\n",
    "            \n",
    "            if (t>=1):\n",
    "                reuse = True\n",
    "            \n",
    "            # Perform one step of the attention mechanism to get back the context vector at step t \n",
    "            self.context = one_step_attention(self.bidirectional_outputs_concat, self.s_prev, Tx, reuse, scope1, scope2)\n",
    "        \n",
    "            # Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "            self.post_attention_lstm_output, state = tf.nn.dynamic_rnn(post_attention_cell, \n",
    "                                                        self.context, initial_state=self.post_attention_state)\n",
    "            \n",
    "            self.post_attention_state = state\n",
    "            self.s_prev = self.post_attention_state[0][1]\n",
    "        \n",
    "            # Apply fully connected layer to the hidden state output of the post-attention LSTM\n",
    "            self.logits = tf.contrib.layers.fully_connected(self.post_attention_lstm_output[:,0,:], \n",
    "                            len(machine_vocab), activation_fn=None,reuse=reuse, \n",
    "                            scope='softmax', weights_initializer = tf.keras.initializers.glorot_uniform())\n",
    "\n",
    "            self.predictions = tf.nn.softmax(self.logits,axis=1)\n",
    "            \n",
    "            logits_list.append(self.logits)\n",
    "            predictions_list.append(self.predictions)\n",
    "        \n",
    "\n",
    "        self.logits_list = tf.stack(logits_list)\n",
    "        self.predictions_list = tf.stack(predictions_list)\n",
    "        \n",
    "        self.loss = build_loss(self.predictions_list, self.labels_ , len(machine_vocab), Ty)\n",
    "       \n",
    "        self.accuracy = build_accuracy(self.predictions_list, self.labels_ , len(machine_vocab))\n",
    "        self.optimizer, self.learning_rate = build_optimizer(self.loss, learning_rate, decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_attention_lstm_size = 64\n",
    "post_attention_lstm_layers = 1\n",
    "bi_lstm_size = 32\n",
    "bi_lstm_layers = 1\n",
    "batch_size = 100\n",
    "human_vocab_size = len(human_vocab)\n",
    "learning_rate = 0.005\n",
    "decay_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0221 01:34:29.302094 140173553436480 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0221 01:34:29.302865 140173553436480 deprecation.py:323] From <ipython-input-15-3fc5a43386fa>:4: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0221 01:34:29.303718 140173553436480 deprecation.py:323] From <ipython-input-15-3fc5a43386fa>:8: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "W0221 01:34:29.309525 140173553436480 deprecation.py:323] From <ipython-input-20-ef842a8ae907>:28: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "W0221 01:34:29.310400 140173553436480 deprecation.py:323] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0221 01:34:29.561030 140173553436480 deprecation.py:506] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0221 01:34:29.568968 140173553436480 deprecation.py:506] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0221 01:34:29.842390 140173553436480 deprecation.py:323] From /home/vgkortsas/.conda/envs/TensorFlow_practice/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0221 01:34:30.310182 140173553436480 deprecation.py:506] From <ipython-input-16-2e0abb696da5>:14: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(69, 128) dtype=float32_ref>\n",
      "shape of weight matrix:  (69, 128)\n",
      "number of trainable parameters:  8832\n",
      "------------------------------\n",
      "<tf.Variable 'bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "shape of weight matrix:  (128,)\n",
      "number of trainable parameters:  128\n",
      "------------------------------\n",
      "<tf.Variable 'bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(69, 128) dtype=float32_ref>\n",
      "shape of weight matrix:  (69, 128)\n",
      "number of trainable parameters:  8832\n",
      "------------------------------\n",
      "<tf.Variable 'bidirectional_rnn/bw/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(128,) dtype=float32_ref>\n",
      "shape of weight matrix:  (128,)\n",
      "number of trainable parameters:  128\n",
      "------------------------------\n",
      "<tf.Variable 'densor1/weights:0' shape=(128, 10) dtype=float32_ref>\n",
      "shape of weight matrix:  (128, 10)\n",
      "number of trainable parameters:  1280\n",
      "------------------------------\n",
      "<tf.Variable 'densor1/biases:0' shape=(10,) dtype=float32_ref>\n",
      "shape of weight matrix:  (10,)\n",
      "number of trainable parameters:  10\n",
      "------------------------------\n",
      "<tf.Variable 'densor2/weights:0' shape=(10, 1) dtype=float32_ref>\n",
      "shape of weight matrix:  (10, 1)\n",
      "number of trainable parameters:  10\n",
      "------------------------------\n",
      "<tf.Variable 'densor2/biases:0' shape=(1,) dtype=float32_ref>\n",
      "shape of weight matrix:  (1,)\n",
      "number of trainable parameters:  1\n",
      "------------------------------\n",
      "<tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(128, 256) dtype=float32_ref>\n",
      "shape of weight matrix:  (128, 256)\n",
      "number of trainable parameters:  32768\n",
      "------------------------------\n",
      "<tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>\n",
      "shape of weight matrix:  (256,)\n",
      "number of trainable parameters:  256\n",
      "------------------------------\n",
      "<tf.Variable 'softmax/weights:0' shape=(64, 11) dtype=float32_ref>\n",
      "shape of weight matrix:  (64, 11)\n",
      "number of trainable parameters:  704\n",
      "------------------------------\n",
      "<tf.Variable 'softmax/biases:0' shape=(11,) dtype=float32_ref>\n",
      "shape of weight matrix:  (11,)\n",
      "number of trainable parameters:  11\n",
      "------------------------------\n",
      "total number of trainable parameters:  52960\n"
     ]
    }
   ],
   "source": [
    "model = machine_translation_model(human_vocab_size=human_vocab_size, batch_size=batch_size, \n",
    "                       bi_lstm_size=bi_lstm_size, bi_lstm_layers=bi_lstm_layers, post_attention_lstm_size=post_attention_lstm_size,\n",
    "                        post_attention_lstm_layers=post_attention_lstm_layers, learning_rate=learning_rate, Tx=Tx, Ty=Ty)\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        print(variable)\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print('shape of weight matrix: ',shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print('number of trainable parameters: ',variable_parameters)\n",
    "        print('------------------------------')\n",
    "        total_parameters += variable_parameters\n",
    "    print('total number of trainable parameters: ',total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explanation of weight matrices shapes\n",
    "\n",
    "* The training variables are:\n",
    "    * Variable:  bidirectional_rnn/fw/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, Shape:  (68, 128)\n",
    "       \n",
    "      68 because the input to each LSTM gate is the concatenation of inputs of size (100,36) and the 32 LSTM nodes, thus (100,68)\n",
    "      \n",
    "      128 because LSTM has 4 gates with 32 nodes and thus 4*32=128\n",
    "     \n",
    "    * Variable:  rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, Shape: (128, 256)\n",
    "      \n",
    "      This refers to the post-attention LSTM, which has inputs conext and s_prev\n",
    "      context has shape (100,1,64), since bidirectional_outputs_concat has shape (100,30,64)\n",
    "      \n",
    "      128 because 64 from context and 64 from LSTM nodes\n",
    "      \n",
    "      256 because LSTM has 4 gates with 64 nodes and thus 4*64=256\n",
    "      \n",
    "    * Variable:  softmax/softmax_w:0, Shape: (64, 11)\n",
    "    \n",
    "      64 because the input to softmax is the output of post-attention LSTM which has 64 nodes\n",
    "      \n",
    "      11 are the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000 Train loss (mean) : 16.5775203705 Accuracy (mean): 0.000000 learning rate : 0.00250000\n",
      "Epoch: 11/5000 Train loss (mean) : 1.4584093094 Accuracy (mean): 0.648200 learning rate : 0.00041667\n",
      "Epoch: 21/5000 Train loss (mean) : 0.4140474796 Accuracy (mean): 0.925100 learning rate : 0.00022727\n",
      "Epoch: 31/5000 Train loss (mean) : 0.1879713386 Accuracy (mean): 0.970900 learning rate : 0.00015625\n",
      "Epoch: 41/5000 Train loss (mean) : 0.1011791602 Accuracy (mean): 0.988200 learning rate : 0.00011905\n",
      "Epoch: 51/5000 Train loss (mean) : 0.0603768937 Accuracy (mean): 0.995300 learning rate : 0.00009615\n",
      "Epoch: 61/5000 Train loss (mean) : 0.0384733528 Accuracy (mean): 0.998000 learning rate : 0.00008065\n",
      "Epoch: 71/5000 Train loss (mean) : 0.0253517050 Accuracy (mean): 0.999200 learning rate : 0.00006944\n",
      "Epoch: 81/5000 Train loss (mean) : 0.0170362908 Accuracy (mean): 0.999900 learning rate : 0.00006098\n",
      "Epoch: 91/5000 Train loss (mean) : 0.0116962399 Accuracy (mean): 1.000000 learning rate : 0.00005435\n",
      "Epoch: 101/5000 Train loss (mean) : 0.0081962887 Accuracy (mean): 1.000000 learning rate : 0.00004902\n",
      "Epoch: 111/5000 Train loss (mean) : 0.0058010761 Accuracy (mean): 1.000000 learning rate : 0.00004464\n",
      "Epoch: 121/5000 Train loss (mean) : 0.0041509657 Accuracy (mean): 1.000000 learning rate : 0.00004098\n",
      "Epoch: 131/5000 Train loss (mean) : 0.0029805573 Accuracy (mean): 1.000000 learning rate : 0.00003788\n",
      "Epoch: 141/5000 Train loss (mean) : 0.0021505549 Accuracy (mean): 1.000000 learning rate : 0.00003521\n",
      "Epoch: 151/5000 Train loss (mean) : 0.0015639716 Accuracy (mean): 1.000000 learning rate : 0.00003289\n",
      "Epoch: 161/5000 Train loss (mean) : 0.0011368124 Accuracy (mean): 1.000000 learning rate : 0.00003086\n",
      "Epoch: 171/5000 Train loss (mean) : 0.0008331476 Accuracy (mean): 1.000000 learning rate : 0.00002907\n",
      "Epoch: 181/5000 Train loss (mean) : 0.0006143479 Accuracy (mean): 1.000000 learning rate : 0.00002747\n",
      "Epoch: 191/5000 Train loss (mean) : 0.0004534148 Accuracy (mean): 1.000000 learning rate : 0.00002604\n",
      "Epoch: 201/5000 Train loss (mean) : 0.0003353843 Accuracy (mean): 1.000000 learning rate : 0.00002475\n",
      "Epoch: 401/5000 Train loss (mean) : 0.0000026270 Accuracy (mean): 1.000000 learning rate : 0.00001244\n",
      "Epoch: 601/5000 Train loss (mean) : 0.0000012147 Accuracy (mean): 1.000000 learning rate : 0.00000831\n",
      "Epoch: 801/5000 Train loss (mean) : 0.0000011961 Accuracy (mean): 1.000000 learning rate : 0.00000623\n",
      "Epoch: 1001/5000 Train loss (mean) : 0.0000011934 Accuracy (mean): 1.000000 learning rate : 0.00000499\n",
      "Epoch: 1201/5000 Train loss (mean) : 0.0000011928 Accuracy (mean): 1.000000 learning rate : 0.00000416\n",
      "Epoch: 1401/5000 Train loss (mean) : 0.0000011925 Accuracy (mean): 1.000000 learning rate : 0.00000357\n",
      "Epoch: 1601/5000 Train loss (mean) : 0.0000011924 Accuracy (mean): 1.000000 learning rate : 0.00000312\n",
      "Epoch: 1801/5000 Train loss (mean) : 0.0000011923 Accuracy (mean): 1.000000 learning rate : 0.00000277\n",
      "Epoch: 2001/5000 Train loss (mean) : 0.0000011923 Accuracy (mean): 1.000000 learning rate : 0.00000250\n",
      "Epoch: 2501/5000 Train loss (mean) : 0.0000011922 Accuracy (mean): 1.000000 learning rate : 0.00000200\n",
      "Epoch: 3001/5000 Train loss (mean) : 0.0000011922 Accuracy (mean): 1.000000 learning rate : 0.00000167\n",
      "Epoch: 3501/5000 Train loss (mean) : 0.0000011922 Accuracy (mean): 1.000000 learning rate : 0.00000143\n",
      "Epoch: 4001/5000 Train loss (mean) : 0.0000011921 Accuracy (mean): 1.000000 learning rate : 0.00000125\n",
      "Epoch: 4501/5000 Train loss (mean) : 0.0000011921 Accuracy (mean): 1.000000 learning rate : 0.00000111\n",
      "duration: 28326.5 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "nb_epochs = 5000\n",
    "epochs = nb_epochs\n",
    "\n",
    "model = machine_translation_model(human_vocab_size=human_vocab_size, batch_size=batch_size, \n",
    "                       bi_lstm_size=bi_lstm_size, bi_lstm_layers=bi_lstm_layers, post_attention_lstm_size=post_attention_lstm_size,\n",
    "                        post_attention_lstm_layers=post_attention_lstm_layers, learning_rate=learning_rate, Tx=Tx, Ty=Ty)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=epochs) \n",
    "\n",
    "train_loss_mean = []\n",
    "train_acc_mean = []\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        \n",
    "        post_attention_state_val = sess.run(model.post_attention_initial_state)\n",
    "         \n",
    "        # shuffling the data\n",
    "        permutated = np.arange(X_train_original.shape[0])\n",
    "        np.random.shuffle(permutated)\n",
    "        X_train = X_train_original[permutated]\n",
    "        Y_train = Y_train_original[permutated]\n",
    "\n",
    "        for (x_train, y_train) in get_batches(X_train, Y_train, batch_size):\n",
    "            feed = {model.inputs_: x_train,\n",
    "                   model.labels_: y_train,\n",
    "                   model.post_attention_initial_state: post_attention_state_val}\n",
    "                       \n",
    "            batch_loss, batch_accuracy,_,batch_learning_rate = sess.run([model.loss,\n",
    "                                                        model.accuracy,\n",
    "                                                        model.optimizer, model.learning_rate],\n",
    "                                feed_dict=feed)\n",
    "           \n",
    "            train_loss.append(batch_loss)\n",
    "            train_acc.append(batch_accuracy)\n",
    "                                    \n",
    "        if (e<=200):\n",
    "            if (e%10==0):\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Train loss (mean) : {:.10f}\".format(np.mean(train_loss)),\n",
    "                      \"Accuracy (mean): {:.6f}\".format(np.mean(train_acc)),\n",
    "                       \"learning rate : {:.8f}\".format(batch_learning_rate))\n",
    "        elif (e>200 and e < 2000):\n",
    "            if (e%200==0):\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Train loss (mean) : {:.10f}\".format(np.mean(train_loss)),\n",
    "                      \"Accuracy (mean): {:.6f}\".format(np.mean(train_acc)),\n",
    "                       \"learning rate : {:.8f}\".format(batch_learning_rate))\n",
    "        else:\n",
    "            if (e%500==0):\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                      \"Train loss (mean) : {:.10f}\".format(np.mean(train_loss)),\n",
    "                      \"Accuracy (mean): {:.6f}\".format(np.mean(train_acc)),\n",
    "                      \"learning rate : {:.8f}\".format(batch_learning_rate))            \n",
    "            \n",
    "        train_loss_mean.append(np.mean(train_loss))\n",
    "        train_acc_mean.append(np.mean(train_acc))\n",
    "\n",
    "        if (e%20 == 0):\n",
    "            saver.save(sess, \"checkpoints/epoch_{}.ckpt\".format(e+1))\n",
    "              \n",
    "    duration=time.time()-start_time\n",
    "    print(\"duration: {:.1f} sec\".format(duration))\n",
    "    saver.save(sess, \"checkpoints/translation.ckpt\")\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1,epochs+1), train_loss_mean)\n",
    "plt.ylabel('mean loss per epoch')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1,epochs+1), train_loss_mean)\n",
    "plt.ylabel('mean loss per epoch - log scale')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale('log')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.arange(1,epochs+1), train_acc_mean)\n",
    "plt.ylabel('mean accuracy per epoch')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model on unseen examples (i.e. human readable dates)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 3 May 1979\n",
      "output: 1979-05-03\n",
      "\n",
      "source: 5 April 09\n",
      "output: 2009-04-05\n",
      "\n",
      "source: 21th of August 2016\n",
      "output: 2016-08-21\n",
      "\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10\n",
      "\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09\n",
      "\n",
      "source: March 3 2001\n",
      "output: 2001-03-03\n",
      "\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03\n",
      "\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01\n",
      "\n",
      "source: 21st of August 2016\n",
      "output: 2016-08-21\n",
      "\n",
      "source: August 21 2016\n",
      "output: 2016-08-21\n",
      "\n",
      "source: 3/27/70\n",
      "output: 1970-03-27\n",
      "\n",
      "source: 18.10.89\n",
      "output: 1989-10-18\n",
      "\n",
      "source: saturday september 29 1984\n",
      "output: 1984-09-29\n",
      "\n",
      "source: 8 01 16\n",
      "output: 2016-01-08\n",
      "\n",
      "source: 12th of November 2032\n",
      "output: 2033-11-12\n",
      "\n",
      "source: 11th of November 2010\n",
      "output: 2010-11-11\n",
      "\n",
      "source: April 3rd 2010\n",
      "output: 2010-04-03\n",
      "\n",
      "source: April 2nd 2010\n",
      "output: 2010-04-02\n",
      "\n",
      "source: April 1st 2010\n",
      "output: 2010-04-01\n",
      "\n",
      "source: December 3rd 2010\n",
      "output: 2010-12-03\n",
      "\n",
      "source: December 3th 2010\n",
      "output: 2010-02-03\n",
      "\n",
      "source: 3rd of December 2010\n",
      "output: 2010-12-03\n",
      "\n",
      "source: 4th of December 2010\n",
      "output: 2010-02-04\n",
      "\n",
      "source: December 4th 2010\n",
      "output: 2010-02-04\n",
      "\n",
      "source: December 5th 2010\n",
      "output: 2010-02-05\n",
      "\n",
      "source: 6th of December 2010\n",
      "output: 2010-12-06\n",
      "\n",
      "source: 11th of August 2016\n",
      "output: 2016-08-11\n",
      "\n",
      "source: Friday 3 May 1995\n",
      "output: 1995-05-03\n",
      "\n",
      "source: 10th June 1900\n",
      "output: 2000-06-10\n",
      "\n",
      "source: 10th June 1980\n",
      "output: 1980-06-10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', \n",
    "            'March 3 2001', 'March 3rd 2001', '1 March 2001', '21st of August 2016', 'August 21 2016',\n",
    "            '3/27/70', '18.10.89','saturday september 29 1984', '8 01 16', '12th of November 2032',\n",
    "           '11th of November 2010', 'April 3rd 2010', 'April 2nd 2010', 'April 1st 2010', 'December 3rd 2010', \n",
    "            'December 3th 2010', '3rd of December 2010', '4th of December 2010', 'December 4th 2010', 'December 5th 2010',\n",
    "           '6th of December 2010', '11th of August 2016', 'Friday 3 May 1995', '10th June 1900','10th June 1980']\n",
    "\n",
    "model = machine_translation_model(human_vocab_size=human_vocab_size, batch_size=1,\n",
    "                       bi_lstm_size=bi_lstm_size, bi_lstm_layers=bi_lstm_layers, post_attention_lstm_size=post_attention_lstm_size,\n",
    "                        post_attention_lstm_layers=post_attention_lstm_layers, learning_rate=learning_rate, Tx=Tx, Ty=Ty,\n",
    "                                     test_mode=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    test_post_attention_state_val = sess.run(model.post_attention_initial_state)\n",
    "        \n",
    "    for example in EXAMPLES:\n",
    "        source = string_to_int(example, Tx, human_vocab)   \n",
    "        x=np.array(source)\n",
    "        x=x.reshape(1,-1)\n",
    "    \n",
    "        batches = get_batches(X_train_original[:1], Y_train_original[:1], 1)\n",
    "        x1, y = next(batches)\n",
    "    \n",
    "        feed = {model.inputs_: x,\n",
    "                   model.labels_: y,\n",
    "                   model.post_attention_initial_state: test_post_attention_state_val}\n",
    "            \n",
    "            \n",
    "        test_predictions_list = sess.run(model.predictions_list,\n",
    "                                feed_dict=feed)\n",
    "        \n",
    "        prediction = np.argmax(test_predictions_list, axis = -1)\n",
    "        output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "        print(\"source:\", example)\n",
    "        print(\"output:\", ''.join(output))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It translates correctly 24 out of the 30 given unseen human readable dates into machine readable format"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "n16CQ",
   "launcher_item_id": "npjGi"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
